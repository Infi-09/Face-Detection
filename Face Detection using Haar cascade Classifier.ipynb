{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84b35a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the opencv library\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2b5078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First convert our RGB images into gray scale to detect faces\n",
    "image = cv2.imread(\"images/batman.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray Scale image\", gray)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb549b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Face Detector class\n",
    "class FaceDetector:\n",
    "    def __init__(self, faceCascadePath):\n",
    "        \"\"\"\n",
    "        Calling the Cascade Classifier function in opencv to detect faces by taking the \n",
    "        haar cascade xml file as the argument (convert serialized xml file (classifier) into \n",
    "        deseralized classifier)\n",
    "        \"\"\"\n",
    "        self.faceCascade = cv2.CascadeClassifier(faceCascadePath)\n",
    "        \n",
    "    def detect(self, image, scaleFactor=1.2, minNeighbors=5, minSize=(30, 30)):\n",
    "        rects = self.faceCascade.detectMultiScale(image,\n",
    "                                                  scaleFactor=scaleFactor,\n",
    "                                                  minNeighbors=minNeighbors,\n",
    "                                                  minSize=minSize,\n",
    "                                                  flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "        return rects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e85be",
   "metadata": {},
   "source": [
    "### Parameters used in the detectMultiScale function \n",
    "**scaleFactor**: How much the image size is reduced at each image scale. This value is used to create the scale pyramid in order to detect faces at multiple scales in the image (some faces may be closer to the foreground, and thus be larger; other faces may be smaller and in the background, thus the usage of varying scales). A value of 1.05 indicates that Jeremy is reducing the size of the image by 5% at each level in the pyramid.                                                                                      \n",
    "\n",
    "**minNeighbors**: How many neighbors each windo w should have for the area in the window to be considered a face. The cascade classifier will detect multiple windows around a face. This parameter controls how many rectangles (neighbors) need to be detected for the window to be labeled a face.\n",
    "\n",
    "**minSize**: A tuple of width and height (in pixels) indicating the minimum size of the window. Bounding boxes smaller than this size are ignored. It is a good idea to start with (30, 30) and fine-tune from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b173518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 4 faces in the image\n"
     ]
    }
   ],
   "source": [
    "# Create a object for Face Detector class\n",
    "fd = FaceDetector('cascade file/haarcascade_frontalface_default.xml')\n",
    "# Call the detect method\n",
    "faceRects = fd.detect(gray, \n",
    "                      scaleFactor=1.2,\n",
    "                      minNeighbors=5,\n",
    "                      minSize=(30, 30))\n",
    "print(f\"I found {len(faceRects)} faces in the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7a422e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (x, y, w, h) in faceRects:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "cv2.imshow(\"Faces\", image)    \n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55baa75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7b52e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
